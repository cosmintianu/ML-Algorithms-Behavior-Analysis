# Project Work Division

## Team Members
- **Cosmin Tianu**  
- **Cosma Razvan**  

## Work Division

### **Task 1: Dataset Generation**  
- **Assigned to:** Cosmin Tianu  
- **Description:** Generate artificial datasets for different machine learning methods.  
#### **Subtasks**  
- [ ] Create datasets with varying:  
  - Number of instances  
  - Number of classes  
  - Class proportions  
  - Point distributions  
  - Decision boundaries  
  - Noise levels  
  - Class overlap  
- [ ] Document dataset properties and how they are useful for different ML methods.  
- [ ] Provide visualizations for each dataset.  

---

### **Task 2: Investigating Method Assumptions**  
- **Assigned to:** Cosma Razvan  
- **Description:** Analyze the assumptions of different ML models and find suitable datasets.  
#### **Subtasks**  
- [ ] Identify datasets where specific ML models perform best while others struggle.  
- [ ] Justify dataset choice for each method:  
  - Logistic Regression  
  - LDA  
  - QDA  
  - Decision Tree (pruned & unpruned)  
  - SVM (linear & RBF)  
- [ ] Validate findings with cross-validation to confirm the best-performing method per dataset.  
- [ ] Summarize findings in a structured report.  

---

### **Task 3: Bias-Variance Tradeoff & Model Complexity**  
- **Assigned to:** Cosmin Tianu  
- **Description:** Study the effect of noise and pruning on Decision Trees.  
#### **Subtasks**  
- [ ] Vary noise levels in a dataset and observe its impact on Decision Trees.  
- [ ] Plot noise level vs. pruning strength (ccp alpha).  
- [ ] Analyze bias-variance tradeoff:  
  - Measure bias and variance error decomposition.  
  - Compare results for different pruning levels.  
- [ ] Interpret the model capacity, bias, variance, and total error.  

---

### **Task 4: Ensemble Learning (Bagging, Random Forest, Boosting)**  
- **Assigned to:** Cosma Razvan  
- **Description:** Compare different ensemble methods on the dataset used for Decision Trees.  
#### **Subtasks**  
- [ ] Train and evaluate:  
  - Bagging  
  - Random Forest  
  - AdaBoost (or another boosting method)  
- [ ] Compare learning curves:  
  - Plot performance vs. the number of trees.  
  - Use Out-of-Bag (OOB) estimates.  
- [ ] Validate models with cross-validation and compare results.  
- [ ] Discuss findings on why certain ensemble methods perform better.  

---

### **Task 5: Report & Presentation**  
- **Both Members (Collaborative Task)**  
- **Description:** Compile results, write the final report, and prepare the presentation.  
#### **Subtasks**  
- [ ] Write a structured report including:  
  - Cover page with authors, title, and date.  
  - Methodology and results.  
  - Discussion of key findings.  
  - References and appendix (if needed).  
- [ ] Prepare a presentation (both members present in class).  
- [ ] Ensure all team members understand each section for evaluation purposes.  

---

## **Notes**  
- Each team member should document their approach clearly.  
- Code should be well-commented for reproducibility.  
- Results should be well-organized with visualizations and tables.  
